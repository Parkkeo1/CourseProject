{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "options = Options()\n",
    "options.headless = True\n",
    "driver = webdriver.Chrome(\"./chromedriver\", options=options)\n",
    "\n",
    "# uses webdriver object to execute javascript code and get dynamically loaded webcontent\n",
    "def get_js_soup(url, driver):\n",
    "    driver.get(url)\n",
    "    res_html = driver.execute_script(\"return document.body.innerHTML\")\n",
    "    soup = BeautifulSoup(res_html,\"html.parser\")\n",
    "    return clean_soup(soup)\n",
    "\n",
    "def clean_soup(soup):\n",
    "    for scr in soup.find_all(['script', 'img']):\n",
    "        scr.decompose()\n",
    "    return soup\n",
    "\n",
    "def get_tags_with_matching_classes(key_classes_set, soup):\n",
    "    def is_any_class_match(css_class):\n",
    "        if css_class is None:\n",
    "            return False\n",
    "        \n",
    "        class_tokens =  set(re.split(r'\\s|-', css_class.lower())) # sdap, profile, field, links, research, etc\n",
    "        return len(class_tokens.intersection(key_classes_set)) > 0\n",
    "    \n",
    "    matches = []\n",
    "    for match in soup.find_all(class_=is_any_class_match):\n",
    "        matches = [m for m in matches if match not in m.descendants]\n",
    "        matches.append(match)\n",
    "\n",
    "    return matches\n",
    "\n",
    "def get_faculty_html_tags_from_url(url, key_classes):\n",
    "    soup = get_js_soup(curr_faculty_url, driver)\n",
    "    matching_tags = get_tags_with_matching_classes(key_classes, soup)\n",
    "    return matching_tags\n",
    "\n",
    "def save_faculty_html_tags(filename, tags):\n",
    "    with open(filename, \"w\") as f:\n",
    "        for t in tags:\n",
    "            f.write(str(t))\n",
    "\n",
    "def get_faculty_text_from_tags(tags):\n",
    "    faculty_page_text = ' '.join([res.get_text() for res in tags])\n",
    "    cleaned_faculty_page_text = re.sub(\"\\s+\", \" \", faculty_page_text).strip()\n",
    "    return cleaned_faculty_page_text\n",
    "\n",
    "def save_faculty_text(filename, text):\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(text)\n",
    "\n",
    "# test gensim's LDA with chbe prof bio content\n",
    "# construct rules for each dept in engr by having a prototype faculty member page HTML for each dept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "chbe_key_classes = set([\n",
    "    \"profile\",\n",
    "    \"biography\",\n",
    "    \"research\",\n",
    "    \"education\",\n",
    "    \"email\",\n",
    "    \"phone\",\n",
    "    \"title\"\n",
    "])\n",
    "\n",
    "save_folder = \"data/chbe/\"\n",
    "chbe_urls = \"chbe_faculty_page_urls.txt\"\n",
    "\n",
    "with open(chbe_urls) as f:\n",
    "    chbe_faculty_urls = [s.strip() for s in f.readlines()]\n",
    "    \n",
    "for url in chbe_faculty_urls:\n",
    "    tags = get_faculty_html_tags_from_url(url, chbe_key_classes)\n",
    "    faculty_id = url[url.rindex('/')+1:]\n",
    "    text = get_faculty_text_from_tags(tags)\n",
    "    \n",
    "    save_faculty_html_tags(save_folder + \"chbe_\" + faculty_id + \".html\", tags)\n",
    "    save_faculty_text(save_folder + \"chbe_\" + faculty_id + \".txt\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dept_htmls = soup.find_all(\"h3\", \"list-expand-header\")\n",
    "# dept_names = [dh.get_text() for dh in dept_htmls]\n",
    "# pprint(dept_names)\n",
    "\n",
    "# engr_dept_faculty = {\n",
    "#     \"Agricultural and Biological Engineering\": [],\n",
    "#     \"Aerospace Engineering\": [],\n",
    "#     \"Bioengineering\": [],\n",
    "#     \"Civil and Environmental Engineering\": \"\",\n",
    "#     \"Chemical & Biomolecular Engineering\": \"\",\n",
    "#     \"Computer Science\",\n",
    "#     \"Electrical and Computer Engineering\",\n",
    "#     \"Industrial and Enterprise Systems Engineering\",\n",
    "#     \"Materials Science and Engineering\",\n",
    "#     \"Mechanical Science and Engineering\",\n",
    "#     \"Nuclear, Plasma and Radiological Engineering\",\n",
    "#     \"Physics\"\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
